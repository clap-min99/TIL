# scripts/7_xgb_gridsearch.py
# ê°€ì¥ ìµœì ì˜ ë°©ë²•ì„ ì°¾ì•„ì„œ ê°€ì¤‘ì¹˜

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import make_scorer, r2_score
from xgboost import XGBRegressor
from math import sqrt

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('features/apple_features.csv')
X = df.drop(columns=['filename', 'grade', 'SSC'])
y = df['SSC']

# ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# RMSE ê³„ì‚°ìš© ìŠ¤ì½”ì–´ëŸ¬ ìƒì„±
def rmse(y_true, y_pred):
    from sklearn.metrics import mean_squared_error
    return sqrt(mean_squared_error(y_true, y_pred))

rmse_scorer = make_scorer(rmse, greater_is_better=False)

# íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜
param_grid = {
    'n_estimators': [100, 300],
    'max_depth': [4, 6, 8],
    'learning_rate': [0.05, 0.1],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0]
}

# GridSearchCV ìˆ˜í–‰
xgb = XGBRegressor(random_state=42)
grid_search = GridSearchCV(estimator=xgb,
                           param_grid=param_grid,
                           scoring=rmse_scorer,
                           cv=3,
                           verbose=1,
                           n_jobs=-1)

print("\nğŸ” XGBoost Grid Search ì‹œì‘ ì¤‘...")
grid_search.fit(X_train, y_train)

# ìµœì  íŒŒë¼ë¯¸í„° ë° ì„±ëŠ¥ ì¶œë ¥
best_model = grid_search.best_estimator_
best_params = grid_search.best_params_
y_pred = best_model.predict(X_test)

from sklearn.metrics import r2_score, mean_squared_error
r2 = r2_score(y_test, y_pred)
rmse_val = sqrt(mean_squared_error(y_test, y_pred))

print("\nâœ… ìµœì  íŒŒë¼ë¯¸í„°:")
print(best_params)
print(f"\nğŸ“ˆ R^2 Score: {r2:.4f}")
print(f"ğŸ“‰ RMSE: {rmse_val:.4f}")
